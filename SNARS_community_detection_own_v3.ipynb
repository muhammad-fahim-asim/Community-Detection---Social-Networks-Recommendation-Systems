{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9beae8",
   "metadata": {},
   "source": [
    "# SNARS â€“ Community Detection Competition (OWN Implementation, Efficient, Robust)\n",
    "\n",
    "This version fixes a critical K-means convergence bug (previously `prev_inertia=inf` caused an immediate break and `best_labels=None`).\n",
    "\n",
    "Implemented by us:\n",
    "- Robust adjacency CSV reader (auto-sep, NaN cleaning)\n",
    "- Normalized Laplacian\n",
    "- Eigengap K estimation (UNC)\n",
    "- **K-means from scratch** (k-means++ + vectorized distances + multiple restarts)\n",
    "- SNARS output formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b4d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# CONFIGURATION (EDIT THESE)\n",
    "# ==============================\n",
    "\n",
    "GROUP_NAME = \"Muhammad\"\n",
    "AUTHORS = \"Muhammad Fahim Asim\"\n",
    "REPO_URL = \"https://github.com/muhammad-fahim-asim/Community-Detection---Social-Networks-Recommendation-Systems\"\n",
    "\n",
    "BENCHMARK_DIR = \"Dataset\"   # where the benchmark CSVs are\n",
    "OUTPUT_ROOT = \".\"     # write outputs next to this notebook\n",
    "\n",
    "USE_SCIPY_EIGSH = True\n",
    "K_MAX_UNC = 30\n",
    "RANDOM_SEED = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f24207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "_HAVE_SCIPY = False\n",
    "if USE_SCIPY_EIGSH:\n",
    "    try:\n",
    "        import scipy.sparse as sp\n",
    "        from scipy.sparse.linalg import eigsh\n",
    "        _HAVE_SCIPY = True\n",
    "    except Exception:\n",
    "        _HAVE_SCIPY = False\n",
    "        print(\"SciPy not available; using NumPy eigen decomposition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e25d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_benchmark_files(benchmark_dir: str):\n",
    "    return sorted(glob.glob(os.path.join(benchmark_dir, \"*.csv\")))\n",
    "\n",
    "def parse_k_from_filename(path: str):\n",
    "    m = re.search(r\"K\\s*=\\s*(\\d+)\", os.path.basename(path))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def read_adjacency_csv(path: str) -> np.ndarray:\n",
    "    df = pd.read_csv(path, header=None, sep=None, engine=\"python\")\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    df = df.dropna(axis=0, how=\"all\").dropna(axis=1, how=\"all\")\n",
    "    df = df.fillna(0.0)\n",
    "    A = df.to_numpy(dtype=float)\n",
    "\n",
    "    if A.shape[0] != A.shape[1]:\n",
    "        raise ValueError(f\"Adjacency matrix must be square. Got {A.shape} for {path}\")\n",
    "\n",
    "    if not np.isfinite(A).all():\n",
    "        bad = int(np.size(A) - np.isfinite(A).sum())\n",
    "        raise ValueError(f\"Adjacency has {bad} non-finite values after cleaning: {path}\")\n",
    "\n",
    "    np.fill_diagonal(A, 0.0)\n",
    "    A = 0.5 * (A + A.T)\n",
    "    return A\n",
    "\n",
    "def normalized_laplacian(A: np.ndarray):\n",
    "    n = A.shape[0]\n",
    "    deg = A.sum(axis=1)\n",
    "    inv_sqrt = np.zeros_like(deg)\n",
    "    mask = deg > 1e-12\n",
    "    inv_sqrt[mask] = 1.0 / np.sqrt(deg[mask])\n",
    "    S = (A * inv_sqrt[:, None]) * inv_sqrt[None, :]\n",
    "    L = np.eye(n) - S\n",
    "    return L, deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff03d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# OWN K-MEANS (fixed + efficient)\n",
    "# ------------------------------\n",
    "\n",
    "def _kmeans_plus_plus_init(X: np.ndarray, k: int, rng: np.random.Generator):\n",
    "    n, d = X.shape\n",
    "    centers = np.empty((k, d), dtype=float)\n",
    "    centers[0] = X[rng.integers(0, n)]\n",
    "    dist2 = np.sum((X - centers[0])**2, axis=1)\n",
    "\n",
    "    for j in range(1, k):\n",
    "        total = dist2.sum()\n",
    "        if total <= 1e-12:\n",
    "            centers[j:] = X[rng.integers(0, n, size=(k-j))]\n",
    "            break\n",
    "        probs = dist2 / total\n",
    "        centers[j] = X[rng.choice(n, p=probs)]\n",
    "        new_dist2 = np.sum((X - centers[j])**2, axis=1)\n",
    "        dist2 = np.minimum(dist2, new_dist2)\n",
    "    return centers\n",
    "\n",
    "def kmeans_own(\n",
    "    X: np.ndarray,\n",
    "    k: int,\n",
    "    n_init: int = 8,\n",
    "    max_iter: int = 120,\n",
    "    tol: float = 1e-5,\n",
    "    random_state: int = 0\n",
    "):\n",
    "    if not np.isfinite(X).all():\n",
    "        raise ValueError(\"kmeans_own received NaN/inf in X.\")\n",
    "\n",
    "    n, d = X.shape\n",
    "    rng = np.random.default_rng(random_state)\n",
    "\n",
    "    best_inertia = np.inf\n",
    "    best_labels = None\n",
    "\n",
    "    X_norm2 = np.sum(X * X, axis=1, keepdims=True)  # (n,1)\n",
    "\n",
    "    for run in range(n_init):\n",
    "        centers = _kmeans_plus_plus_init(X, k, rng)\n",
    "        centers_norm2 = np.sum(centers * centers, axis=1, keepdims=True).T  # (1,k)\n",
    "\n",
    "        prev_inertia = None  # IMPORTANT: avoid inf bug\n",
    "        for it in range(max_iter):\n",
    "            dist2 = X_norm2 + centers_norm2 - 2.0 * (X @ centers.T)  # (n,k)\n",
    "            labels = np.argmin(dist2, axis=1)\n",
    "\n",
    "            # update centers\n",
    "            new_centers = np.zeros_like(centers)\n",
    "            counts = np.bincount(labels, minlength=k).astype(float)\n",
    "            for j in range(k):\n",
    "                if counts[j] > 0:\n",
    "                    new_centers[j] = X[labels == j].mean(axis=0)\n",
    "                else:\n",
    "                    new_centers[j] = X[rng.integers(0, n)]\n",
    "            centers = new_centers\n",
    "            centers_norm2 = np.sum(centers * centers, axis=1, keepdims=True).T\n",
    "\n",
    "            inertia = float(np.sum(np.min(dist2, axis=1)))\n",
    "            if not np.isfinite(inertia):\n",
    "                prev_inertia = None\n",
    "                break\n",
    "\n",
    "            if prev_inertia is not None:\n",
    "                if abs(prev_inertia - inertia) <= tol * max(1.0, prev_inertia):\n",
    "                    break\n",
    "            prev_inertia = inertia\n",
    "\n",
    "        if prev_inertia is not None and prev_inertia < best_inertia:\n",
    "            best_inertia = prev_inertia\n",
    "            best_labels = labels.copy()\n",
    "\n",
    "    if best_labels is None:\n",
    "        raise ValueError(\"kmeans_own failed: best_labels is None (unexpected).\")\n",
    "\n",
    "    return best_labels, best_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11fb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_normalize(U: np.ndarray, eps: float = 1e-12):\n",
    "    norms = np.linalg.norm(U, axis=1, keepdims=True)\n",
    "    return U / np.maximum(norms, eps)\n",
    "\n",
    "def smallest_eigs(L: np.ndarray, k: int):\n",
    "    n = L.shape[0]\n",
    "    k = int(min(k, n-1))\n",
    "    if _HAVE_SCIPY and n >= 250:\n",
    "        vals, vecs = eigsh(sp.csr_matrix(L), k=k, which=\"SM\")\n",
    "        order = np.argsort(vals)\n",
    "        return np.real(vals[order]), np.real(vecs[:, order])\n",
    "    vals, vecs = np.linalg.eigh(L)\n",
    "    return np.real(vals[:k]), np.real(vecs[:, :k])\n",
    "\n",
    "def estimate_k_eigengap(L: np.ndarray, k_max: int = 30):\n",
    "    n = L.shape[0]\n",
    "    k_max = int(min(k_max, max(2, n-1)))\n",
    "    vals, _ = smallest_eigs(L, k_max)\n",
    "    gaps = np.diff(vals)\n",
    "    if len(gaps) < 2:\n",
    "        return 2, vals\n",
    "    start = 1\n",
    "    idx = int(np.argmax(gaps[start:]) + start)\n",
    "    return max(2, idx + 1), vals\n",
    "\n",
    "def spectral_clustering_own(A: np.ndarray, k: int, random_state: int = 0):\n",
    "    L, _ = normalized_laplacian(A)\n",
    "    _, vecs = smallest_eigs(L, k)\n",
    "    U = row_normalize(vecs)\n",
    "    if not np.isfinite(U).all():\n",
    "        raise ValueError(\"Embedding U contains NaN/inf.\")\n",
    "    labels0, _ = kmeans_own(U, k, n_init=12, max_iter=250, tol=1e-6, random_state=random_state)\n",
    "    return labels0 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb43b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_assignment_csv(path_out: str, labels1: np.ndarray):\n",
    "    with open(path_out, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, lab in enumerate(labels1, start=1):\n",
    "            f.write(f\"{i}, {int(lab)}\\n\")\n",
    "\n",
    "def run_on_file(path: str, out_dir: str, k_max_unc: int = 30):\n",
    "    t0 = time.perf_counter()\n",
    "    A = read_adjacency_csv(path)\n",
    "    k = parse_k_from_filename(path)\n",
    "    if k is None:\n",
    "        L, _ = normalized_laplacian(A)\n",
    "        k, _ = estimate_k_eigengap(L, k_max=k_max_unc)\n",
    "\n",
    "    labels1 = spectral_clustering_own(A, k, random_state=RANDOM_SEED)\n",
    "    dt = time.perf_counter() - t0\n",
    "\n",
    "    out_csv = os.path.join(out_dir, os.path.basename(path))\n",
    "    write_assignment_csv(out_csv, labels1)\n",
    "    return dt, k, A.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a4c658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset\\\\D1-K=2.csv',\n",
       " 'Dataset\\\\D1-UNC.csv',\n",
       " 'Dataset\\\\D2-K=7.csv',\n",
       " 'Dataset\\\\D2-UNC.csv',\n",
       " 'Dataset\\\\D3-K=12.csv',\n",
       " 'Dataset\\\\D3-UNC.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==============================\n",
    "# RUN ALL BENCHMARK FILES\n",
    "# ==============================\n",
    "\n",
    "benchmark_files = list_benchmark_files(BENCHMARK_DIR)\n",
    "benchmark_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aadd4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK   D1-K=2.csv   n=34   K=2   time=0.0317s\n",
      "OK   D1-UNC.csv   n=125   K=25   time=0.0803s\n",
      "OK   D2-K=7.csv   n=62   K=7   time=0.0206s\n",
      "OK   D2-UNC.csv   n=150   K=15   time=0.0681s\n",
      "OK   D3-K=12.csv   n=115   K=12   time=0.0499s\n",
      "OK   D3-UNC.csv   n=81   K=9   time=0.0414s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>execution_time_s</th>\n",
       "      <th>k_used</th>\n",
       "      <th>n_vertices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D1-K=2.csv</td>\n",
       "      <td>0.031662</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D1-UNC.csv</td>\n",
       "      <td>0.080288</td>\n",
       "      <td>25</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D2-K=7.csv</td>\n",
       "      <td>0.020641</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D2-UNC.csv</td>\n",
       "      <td>0.068129</td>\n",
       "      <td>15</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D3-K=12.csv</td>\n",
       "      <td>0.049921</td>\n",
       "      <td>12</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D3-UNC.csv</td>\n",
       "      <td>0.041410</td>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name  execution_time_s  k_used  n_vertices\n",
       "0   D1-K=2.csv          0.031662       2          34\n",
       "1   D1-UNC.csv          0.080288      25         125\n",
       "2   D2-K=7.csv          0.020641       7          62\n",
       "3   D2-UNC.csv          0.068129      15         150\n",
       "4  D3-K=12.csv          0.049921      12         115\n",
       "5   D3-UNC.csv          0.041410       9          81"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir = os.path.join(OUTPUT_ROOT, GROUP_NAME)\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "results_rows = []\n",
    "for path in benchmark_files:\n",
    "    try:\n",
    "        dt, k_used, n = run_on_file(path, out_dir=out_dir, k_max_unc=K_MAX_UNC)\n",
    "        results_rows.append((os.path.basename(path), dt, k_used, n))\n",
    "        print(f\"OK   {os.path.basename(path)}   n={n}   K={k_used}   time={dt:.4f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"FAIL {os.path.basename(path)}   error={e}\")\n",
    "\n",
    "pd.DataFrame(results_rows, columns=[\"file_name\", \"execution_time_s\", \"k_used\", \"n_vertices\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "020dc8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: .\\Muhammad\\description.txt\n",
      "Outputs folder: .\\Muhammad\n"
     ]
    }
   ],
   "source": [
    "# Write description.txt (required)\n",
    "\n",
    "desc_path = os.path.join(out_dir, \"description.txt\")\n",
    "with open(desc_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"{AUTHORS}\\n\")\n",
    "    f.write(f\"{REPO_URL}\\n\")\n",
    "    for file_name, dt, k_used, n in results_rows:\n",
    "        f.write(f\"{{{file_name}, {dt:.6f}}}\\n\")\n",
    "\n",
    "print(\"Wrote:\", desc_path)\n",
    "print(\"Outputs folder:\", out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
